- Use cases
  - Asynchronous messaging (low-latency)
  - Real time stream processing. (As messages arrive the consumer can consume them immediately).
  - Logging and monitoring
  - Event sourcing pattern: State of entity could be detected and analyzed.
  - Real time analytics
- Kafka Messages
  - Unit of data
    - Row, record, map, blob
  - Treats as byte array with no semantic meaning
  - Max message limit is configurable and default is 1 mb
  - Support batch request from producer or consumer
  - Message content
    - Key
      - No mandatory to be unique
      - Used for partitioning
      - Kafka assigns a random key is not provided.
    - Value
      - Content of the message
      - User defined
    - Timestamp
      - Automatically timestamp by kafka
      - There are two types of automatic timestamp
        - Event Time: When producer produce the message
        - Ingestion time: When the broker store the message
      - Type is configurable
- Topics
  - Holder of the messages
  - Queue for similar messages
    - similar means that messages have the same structure and format and also the same producers and consumers.
  - Multiple topics per single kafka instance is supported
  - Every topic supports multiple producers and consumers
  - Consumers consumes messages from the topic
  - Each topic have multiple partitions that physically different.
- Broker
  - Is the Kafka instance running
  - Listen on specific port
  - Receive messages and stores.
  - Subscription management
    - Consumers subscribe to specific topics within the broker.
    - It keeps track of all consumers and what message has been sent to which consumer.
  - Manage topics, partitions and logs
  - Clustering capability.
    - Set of kafka instances with a kafka leader and when one broker goes down another broker will take in place.
- Logs
  - Physical files in which data are stored.
  - Managed by kafka broker.
    - Each broker assigned a Log directory where to store messages.
  - Pruned periodically
    - Logs remain for 7 days by default
  - Physical space management
  - All config: $KAFKA_ROOT/config/server.properties:log.dirs
- Producer
  - Any client that publishes data to kafka
  - Client libraries for programming languages.
  - Multiple concurrent producers per topic
    - It could be different physical processes
    - It could be different threads within a single process
  - Message key identification
    - Also consider to equally distribute and store across partitions.
  - Message serialization to bytes
  - Synchronous and asynchronous options to publish to kafka
    - asynchronous don’t wait for an acknowledgment from the broker to proceed with the next message.
- Consumer
  - Consume message from kafka
  - Consume any time as soon as the message is still stored in the LOG.
  - Multiple concurrent consumer per topic
  - Workload scaling with consumer groups.
  - Deserialize the messages from bytes to original format.
  - Acknowledge the broker once they successfully consumed the message.
- Partitions
  - Each topic can contain multiple partitions
  - Each topic can have 1-n partitions.
  - It allows kafka to scale
    - It enables parallel storing and consumption of messages
  - It provides horizontal scalability.
  - Each partition has separate log files.
  - Each partition has a leader broker. It might be the same leader if we have only one broker.
  - Enable consumers to share workload though consumer groups.
    - As we have multiple partitions we can have multiple consumers for the same topic as one consumer is not sufficient to handle many messages in different partitions.
    - Each message goes to only one consumer in the group.
    - Multiple consumer groups
      - Each group gets all the messages but the message inside the consumer group will be sent to one consumer only .
  - Partitions can be replicated.
  - Each message stored in only one partition
  - If the partition is replicated, each replica will be synced.
  - Message order is guaranteed only within a partition but not across multiple partitions.
  - Same message key = same partition
    - Message with the same key will be in the same partition
  - Partition count can not be decreased after the topic is created.
- Kafka Offsets
  - It’s a number to track message consumption by consumer and partition.
  - Each message arrives to kafka tagged with message Id offset to track its consumption.
  - Broker keeps track of what is sent and what is acknowledged to/by the consumer
  - Current offset: last message sent to a given consumer.
  - Committed offset: last message acknowledged by the consumer.
  - It’s auto ack on receive by default.
  - if broker didn’t receive acknowledge for the message after a timeout, it will resent the message
  - Ensure at least one delivery of the message to one group consumer.
  - New consumer: request to start receiving message whether from start, new or at specific offset.
    - Start means: It will receive all the messages in the topic.
    - New meaning: It will receive only the new messages.
    - At specific offset
